{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil.parser import parse\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "\n",
    "samplesize = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def _gender(data):\n",
    "    try:\n",
    "        if data and data.lower()=='male': return 1\n",
    "        else: return 0\n",
    "    except: return -1\n",
    "    \n",
    "def _age(data):\n",
    "    try:\n",
    "        if data and str(data) !='nan':\n",
    "            bd = parse(data)\n",
    "            diff = datetime.now() - bd\n",
    "            return diff.days \n",
    "        else: return 0\n",
    "    except Exception as e: \n",
    "        print (e)\n",
    "        print (data)\n",
    "        return -1\n",
    "    \n",
    "def _nationality(data):\n",
    "    if data and 'singapore' in data.lower(): return 1   \n",
    "    else: return 0\n",
    "    \n",
    "def _resi_status(data):\n",
    "    if data and  data.lower() == 'citizen' or  data.lower() == 'pr': return 1   \n",
    "    else: return 0\n",
    "    \n",
    "def _yesno(data):\n",
    "    if data:\n",
    "        if str(data).lower() == 'yes' : return 1 \n",
    "        else: return 0\n",
    "    else: return -1\n",
    "    \n",
    "def _occupation(data):\n",
    "    if data and 'tour' in str(data).lower(): return 1   \n",
    "    else: return 0\n",
    "    \n",
    "def _self_employ_time(data):\n",
    "    import calendar\n",
    "    try:\n",
    "        if data and str(data) != 'nan':\n",
    "            \n",
    "            \n",
    "            _m = list(calendar.month_abbr).index(data.split(\";\")[0]) \n",
    "\n",
    "            \n",
    "\n",
    "            __y = data.split(\";\")[1].replace('Before','').replace(' ','') # get rid of silly \"Before\"\n",
    "            _y = int(__y)\n",
    "\n",
    "            #print ( (datetime.now() -   datetime(_y,_m,1)).days)\n",
    "            return (datetime.now() -   datetime(_y,_m,1)).days\n",
    "            #else: \n",
    "            #    ym = data.split(';')[2]\n",
    "            #    _y = int(ym.split(\"-\")[0])\n",
    "            #    _m = int(ym.split(\"-\")[1])\n",
    "            #    return (datetime.now() -   datetime(_y,_m,1)).days\n",
    "                \n",
    "        else: return 0\n",
    "    except Exception as e: \n",
    "        print ('mthyear exception')\n",
    "        print (data)\n",
    "        print (e)\n",
    "        return 0\n",
    "    \n",
    "def _log(data):\n",
    "    try:\n",
    "        #print (para)\n",
    "        if data and float(data)>0:return math.log10(float(data))\n",
    "        else: return 0\n",
    "    except Exception as e: \n",
    "        #print (e)\n",
    "        return -1\n",
    "def _int(data):\n",
    "    if data and str(data) != 'nan': return int(data)\n",
    "    else: return 0\n",
    "    \n",
    "    \n",
    "from textblob import TextBlob #sentiment analysis\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "import statistics\n",
    "def _sentiment_of(text):\n",
    "    if text:\n",
    "        blob = TextBlob(str(text))\n",
    "        _sentiments = []\n",
    "        for sentence in blob.sentences:\n",
    "            _sentiments.append(sentence.sentiment.polarity)\n",
    "        return  statistics.mean(_sentiments) \n",
    "    else: return 0\n",
    "    \n",
    "def _interested(data):\n",
    "    if data and 'contact' in str(data): return 1\n",
    "    else: return 0\n",
    "    \n",
    "def _label_outcome(data):\n",
    "    if data:\n",
    "        if str(data) == 'Approve - 1000': return 1000\n",
    "        elif str(data) == 'Approve - 800': return 800\n",
    "        elif str(data) == 'Approve - 400': return 400\n",
    "        else: return 0\n",
    "    else: return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv('output2.csv', dtype='unicode') # this is the final file!\n",
    "\n",
    "\n",
    "#_result = df[0:samplesize]\n",
    "_result = df\n",
    "print ('start')\n",
    "old_columns = [i for i in _result.columns]\n",
    "\n",
    "_result['_gender']=_result['Gender'].apply(_gender)\n",
    "_result['_age']=_result['Date of Birth'].apply(_age)\n",
    "_result['_nationality']=_result['Nationality'].apply(_nationality)\n",
    "_result['_resi_status']=_result['Residential Status'].apply(_resi_status)\n",
    "\n",
    "_result = pd.concat([_result,pd.get_dummies(_result['Housing Type'], prefix='onehot')],axis=1)\n",
    "_result['_hdb_registered_address']=_result['Registered Address'].apply(_yesno)\n",
    "_result = pd.concat([_result,pd.get_dummies(_result['Highest Education'], prefix='onehot')],axis=1)\n",
    "_result['_occupation']=_result['Occupation'].apply(_occupation)\n",
    "#_result['_av']=_result['Annual Value (AV) of  registered address'].apply(_av,args=(-1,))\n",
    "_result['_av_value']=_result['Annual Value (AV) of  registered address'].apply(_log)\n",
    "\n",
    "_result['__temp']=_result['Self Employed Since (Month)']+';'+_result['Self Employed Since (Year)']\n",
    "_result['_self_employ_time']=_result['__temp'].apply(_self_employ_time)\n",
    "\n",
    "print ('50%') \n",
    "_result['_2018_t']=_result['Income in 2018 (NOA YA2019) - Trade income'].apply(_log)\n",
    "_result['_2018_e']=_result['\\xa0Income in 2018 (NOA YA2019) - Employment income'].apply(_log)\n",
    "_result['_2019_e']=_result['Income in 2019 (NOA YA2020) - Trade income'].apply(_log)\n",
    "_result['_2019_t']=_result['Income in 2019 (NOA YA2020) - Employment income'].apply(_log)\n",
    "_result['_2020_e']=_result['Income in 2020 (Jan-Mar) - Trade income'].apply(_log)\n",
    "_result['_2020_t']=_result['Income in 2020 (Jan-Mar) - Employment income'].apply(_log)\n",
    "_result['s_2019_i']=_result['Spouse\\'s Income in 2019'].apply(_log)\n",
    "_result['s_2020_i']=_result['Spouse\\'s Income in 2020 (Jan-Mar)'].apply(_log)\n",
    "\n",
    "_result['_child']=_result['No. of Singaporean Children < 21'].apply(_int)\n",
    "_result['_parent']=_result['No. of Singaporean Parents > 64'].apply(_int)\n",
    "\n",
    "_result = pd.concat([_result,pd.get_dummies(_result['Marital Status'], prefix='onehot')],axis=1)\n",
    "_result['_married']=_result['Marriage Date'].apply(_age)\n",
    "_result['_divorced']=_result['Divorce Date'].apply(_age)\n",
    "\n",
    "_result['_hdb']=_result['Number of HDB properties own'].apply(_int)\n",
    "_result['_pte']=_result['Number of private properties own'].apply(_int)\n",
    "_result['_comz']=_result['Number of commercial properties own'].apply(_int)\n",
    "_result['_comz_av']=_result['Annual Value (AV) of commercial properties own'].apply(_log)\n",
    "_result['_comz_operate']=_result['Biz Operations from  commercial properties'].apply(_yesno)\n",
    "\n",
    "\n",
    "_result['_hardship_sentiment']=_result['Please describe hardship (if any)'].apply(_sentiment_of)\n",
    "_result['_ntuc_covid']=_result['Interested in NTUC Covid19 Programme'].apply(_interested)\n",
    "\n",
    "_result['LABEL']=_result['Final Outcome Combined'].apply(_label_outcome)\n",
    "\n",
    "\n",
    "_result = _result.drop(old_columns,axis=1)\n",
    "print ('end')\n",
    "\n",
    "_result.to_csv ('_final.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from machine import Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Machine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/150\n",
      "40000/40000 [==============================] - 5s 136us/sample - loss: 22.0500 - accuracy: 0.5324 - val_loss: 4.0148 - val_accuracy: 0.5589\n",
      "Epoch 2/150\n",
      "40000/40000 [==============================] - 3s 67us/sample - loss: 4.1619 - accuracy: 0.5623 - val_loss: 2.1797 - val_accuracy: 0.6124\n",
      "Epoch 3/150\n",
      "40000/40000 [==============================] - 3s 69us/sample - loss: 4.2126 - accuracy: 0.5741 - val_loss: 3.7339 - val_accuracy: 0.4742\n",
      "Epoch 4/150\n",
      "40000/40000 [==============================] - 3s 69us/sample - loss: 3.7202 - accuracy: 0.5807 - val_loss: 2.9225 - val_accuracy: 0.5895\n",
      "Epoch 5/150\n",
      "40000/40000 [==============================] - 3s 68us/sample - loss: 3.5853 - accuracy: 0.5833 - val_loss: 2.3797 - val_accuracy: 0.6672\n",
      "Epoch 6/150\n",
      "40000/40000 [==============================] - 3s 70us/sample - loss: 3.7852 - accuracy: 0.5783 - val_loss: 2.8385 - val_accuracy: 0.5989\n",
      "Epoch 7/150\n",
      "40000/40000 [==============================] - 4s 91us/sample - loss: 3.7682 - accuracy: 0.5827 - val_loss: 8.1566 - val_accuracy: 0.5754\n",
      "Epoch 8/150\n",
      "40000/40000 [==============================] - 3s 79us/sample - loss: 3.9160 - accuracy: 0.5817 - val_loss: 3.2339 - val_accuracy: 0.5753\n",
      "Epoch 9/150\n",
      "40000/40000 [==============================] - 4s 98us/sample - loss: 3.9586 - accuracy: 0.5818 - val_loss: 4.0157 - val_accuracy: 0.6663\n",
      "Epoch 10/150\n",
      "40000/40000 [==============================] - 3s 83us/sample - loss: 3.4146 - accuracy: 0.5958 - val_loss: 2.8024 - val_accuracy: 0.5910\n",
      "Epoch 11/150\n",
      "40000/40000 [==============================] - 4s 102us/sample - loss: 3.4302 - accuracy: 0.5916 - val_loss: 1.8695 - val_accuracy: 0.5562\n",
      "Epoch 12/150\n",
      "40000/40000 [==============================] - 4s 107us/sample - loss: 3.8440 - accuracy: 0.5889 - val_loss: 7.1180 - val_accuracy: 0.6207\n",
      "Epoch 13/150\n",
      "40000/40000 [==============================] - 3s 75us/sample - loss: 3.5461 - accuracy: 0.5844 - val_loss: 2.7084 - val_accuracy: 0.6408\n",
      "Epoch 14/150\n",
      "40000/40000 [==============================] - 3s 72us/sample - loss: 3.1601 - accuracy: 0.5995 - val_loss: 3.5569 - val_accuracy: 0.5483\n",
      "Epoch 15/150\n",
      "40000/40000 [==============================] - 3s 74us/sample - loss: 3.3092 - accuracy: 0.5921 - val_loss: 1.7206 - val_accuracy: 0.6067\n",
      "Epoch 16/150\n",
      "40000/40000 [==============================] - 3s 85us/sample - loss: 3.5289 - accuracy: 0.5905 - val_loss: 1.8231 - val_accuracy: 0.6462\n",
      "Epoch 17/150\n",
      "40000/40000 [==============================] - 4s 92us/sample - loss: 3.0685 - accuracy: 0.5955 - val_loss: 2.3598 - val_accuracy: 0.6359\n",
      "Epoch 18/150\n",
      "40000/40000 [==============================] - 4s 93us/sample - loss: 3.2152 - accuracy: 0.5891 - val_loss: 2.9988 - val_accuracy: 0.6459\n",
      "Epoch 19/150\n",
      "40000/40000 [==============================] - 3s 70us/sample - loss: 3.1291 - accuracy: 0.5925 - val_loss: 2.7486 - val_accuracy: 0.6383\n",
      "Epoch 20/150\n",
      "40000/40000 [==============================] - 3s 69us/sample - loss: 3.4046 - accuracy: 0.5889 - val_loss: 2.1846 - val_accuracy: 0.5978\n",
      "Epoch 21/150\n",
      "40000/40000 [==============================] - 3s 72us/sample - loss: 3.0056 - accuracy: 0.5967 - val_loss: 2.2031 - val_accuracy: 0.6357\n",
      "Epoch 22/150\n",
      "40000/40000 [==============================] - 3s 71us/sample - loss: 3.0958 - accuracy: 0.5906 - val_loss: 1.9407 - val_accuracy: 0.5863\n",
      "Epoch 23/150\n",
      "40000/40000 [==============================] - 3s 77us/sample - loss: 3.0537 - accuracy: 0.5949 - val_loss: 3.6878 - val_accuracy: 0.5403\n",
      "Epoch 24/150\n",
      "40000/40000 [==============================] - 3s 83us/sample - loss: 3.0174 - accuracy: 0.5966 - val_loss: 1.1098 - val_accuracy: 0.6434\n",
      "Epoch 25/150\n",
      "40000/40000 [==============================] - 3s 83us/sample - loss: 3.1985 - accuracy: 0.5889 - val_loss: 4.0638 - val_accuracy: 0.5380\n",
      "Epoch 26/150\n",
      "40000/40000 [==============================] - 3s 72us/sample - loss: 3.0595 - accuracy: 0.5944 - val_loss: 2.5728 - val_accuracy: 0.6445\n",
      "Epoch 27/150\n",
      "40000/40000 [==============================] - 4s 93us/sample - loss: 2.9377 - accuracy: 0.6012 - val_loss: 1.9333 - val_accuracy: 0.6691\n",
      "Epoch 28/150\n",
      "40000/40000 [==============================] - 4s 89us/sample - loss: 3.3749 - accuracy: 0.5853 - val_loss: 3.5953 - val_accuracy: 0.5974\n",
      "Epoch 29/150\n",
      "40000/40000 [==============================] - 3s 75us/sample - loss: 3.1761 - accuracy: 0.5915 - val_loss: 2.9162 - val_accuracy: 0.5173\n",
      "Epoch 30/150\n",
      "40000/40000 [==============================] - 3s 75us/sample - loss: 2.6649 - accuracy: 0.6044 - val_loss: 2.1295 - val_accuracy: 0.6198\n",
      "Epoch 31/150\n",
      "40000/40000 [==============================] - 3s 80us/sample - loss: 3.1008 - accuracy: 0.5938 - val_loss: 2.8772 - val_accuracy: 0.4985\n",
      "Epoch 32/150\n",
      "40000/40000 [==============================] - 3s 80us/sample - loss: 2.9316 - accuracy: 0.5920 - val_loss: 1.3629 - val_accuracy: 0.6276\n",
      "Epoch 33/150\n",
      "40000/40000 [==============================] - 3s 82us/sample - loss: 2.6783 - accuracy: 0.5941 - val_loss: 3.3598 - val_accuracy: 0.6317\n",
      "Epoch 34/150\n",
      "40000/40000 [==============================] - 3s 79us/sample - loss: 2.7530 - accuracy: 0.6002 - val_loss: 1.6410 - val_accuracy: 0.5880\n",
      "Epoch 35/150\n",
      "40000/40000 [==============================] - 4s 96us/sample - loss: 2.4702 - accuracy: 0.6037 - val_loss: 3.8983 - val_accuracy: 0.5189\n",
      "Epoch 36/150\n",
      "40000/40000 [==============================] - 3s 83us/sample - loss: 2.8782 - accuracy: 0.5913 - val_loss: 4.3536 - val_accuracy: 0.5447\n",
      "Epoch 37/150\n",
      "40000/40000 [==============================] - 3s 75us/sample - loss: 2.7036 - accuracy: 0.6020 - val_loss: 4.1308 - val_accuracy: 0.5519\n",
      "Epoch 38/150\n",
      "40000/40000 [==============================] - 3s 75us/sample - loss: 2.7396 - accuracy: 0.6007 - val_loss: 2.6059 - val_accuracy: 0.6101\n",
      "Epoch 39/150\n",
      "40000/40000 [==============================] - 3s 87us/sample - loss: 2.5337 - accuracy: 0.6016 - val_loss: 1.4804 - val_accuracy: 0.6195\n",
      "Epoch 40/150\n",
      "40000/40000 [==============================] - 4s 92us/sample - loss: 2.7902 - accuracy: 0.5990 - val_loss: 2.4072 - val_accuracy: 0.5440\n",
      "Epoch 41/150\n",
      "40000/40000 [==============================] - 3s 82us/sample - loss: 2.8118 - accuracy: 0.5944 - val_loss: 4.0890 - val_accuracy: 0.5694\n",
      "Epoch 42/150\n",
      "40000/40000 [==============================] - 3s 85us/sample - loss: 2.6909 - accuracy: 0.6025 - val_loss: 1.7628 - val_accuracy: 0.6390\n",
      "Epoch 43/150\n",
      "40000/40000 [==============================] - 3s 77us/sample - loss: 2.4279 - accuracy: 0.6029 - val_loss: 2.1479 - val_accuracy: 0.6008\n",
      "Epoch 44/150\n",
      "40000/40000 [==============================] - 3s 83us/sample - loss: 2.7863 - accuracy: 0.5956 - val_loss: 3.8078 - val_accuracy: 0.4752\n",
      "Epoch 45/150\n",
      "40000/40000 [==============================] - 3s 78us/sample - loss: 2.5965 - accuracy: 0.6044 - val_loss: 4.3349 - val_accuracy: 0.4625\n",
      "Epoch 46/150\n",
      "40000/40000 [==============================] - 3s 71us/sample - loss: 2.5557 - accuracy: 0.5993 - val_loss: 1.6594 - val_accuracy: 0.5479\n",
      "Epoch 47/150\n",
      "40000/40000 [==============================] - 3s 79us/sample - loss: 2.4313 - accuracy: 0.5967 - val_loss: 2.2346 - val_accuracy: 0.5787\n",
      "Epoch 48/150\n",
      "40000/40000 [==============================] - 3s 77us/sample - loss: 2.2731 - accuracy: 0.6081 - val_loss: 1.5417 - val_accuracy: 0.6224\n",
      "Epoch 49/150\n",
      "40000/40000 [==============================] - 3s 74us/sample - loss: 2.3104 - accuracy: 0.6022 - val_loss: 1.8642 - val_accuracy: 0.6588\n",
      "Epoch 50/150\n",
      "40000/40000 [==============================] - 3s 71us/sample - loss: 2.6007 - accuracy: 0.5993 - val_loss: 2.1918 - val_accuracy: 0.6212\n",
      "Epoch 51/150\n",
      "40000/40000 [==============================] - 3s 74us/sample - loss: 2.4608 - accuracy: 0.6090 - val_loss: 2.4134 - val_accuracy: 0.5500\n",
      "Epoch 52/150\n",
      "40000/40000 [==============================] - 3s 77us/sample - loss: 2.3775 - accuracy: 0.5964 - val_loss: 1.0592 - val_accuracy: 0.6681\n",
      "Epoch 53/150\n",
      "40000/40000 [==============================] - 3s 74us/sample - loss: 2.2876 - accuracy: 0.6046 - val_loss: 3.0947 - val_accuracy: 0.5960s - los\n",
      "Epoch 54/150\n",
      "40000/40000 [==============================] - 3s 74us/sample - loss: 2.4714 - accuracy: 0.5976 - val_loss: 4.0426 - val_accuracy: 0.4591\n",
      "Epoch 55/150\n",
      "40000/40000 [==============================] - 3s 74us/sample - loss: 2.2481 - accuracy: 0.5991 - val_loss: 1.9451 - val_accuracy: 0.5599\n",
      "Epoch 56/150\n",
      "40000/40000 [==============================] - 3s 71us/sample - loss: 2.4068 - accuracy: 0.5993 - val_loss: 5.0128 - val_accuracy: 0.5388\n",
      "Epoch 57/150\n",
      "40000/40000 [==============================] - 3s 75us/sample - loss: 2.2091 - accuracy: 0.6074 - val_loss: 1.9652 - val_accuracy: 0.5059\n",
      "Epoch 58/150\n",
      "40000/40000 [==============================] - 5s 124us/sample - loss: 2.2538 - accuracy: 0.6088 - val_loss: 2.4242 - val_accuracy: 0.6133\n",
      "Epoch 59/150\n",
      "40000/40000 [==============================] - 3s 68us/sample - loss: 2.1863 - accuracy: 0.6063 - val_loss: 2.4377 - val_accuracy: 0.6233\n",
      "Epoch 60/150\n",
      "40000/40000 [==============================] - 3s 69us/sample - loss: 2.2189 - accuracy: 0.6001 - val_loss: 2.3649 - val_accuracy: 0.5375\n",
      "Epoch 61/150\n",
      "40000/40000 [==============================] - 3s 65us/sample - loss: 2.2555 - accuracy: 0.6023 - val_loss: 1.2432 - val_accuracy: 0.6478\n",
      "Epoch 62/150\n",
      "40000/40000 [==============================] - 3s 63us/sample - loss: 2.1352 - accuracy: 0.6067 - val_loss: 3.8380 - val_accuracy: 0.5859\n",
      "Epoch 63/150\n",
      "40000/40000 [==============================] - 2s 61us/sample - loss: 2.1591 - accuracy: 0.6076 - val_loss: 4.3034 - val_accuracy: 0.6432\n",
      "Epoch 64/150\n",
      "40000/40000 [==============================] - 3s 65us/sample - loss: 2.0601 - accuracy: 0.6089 - val_loss: 1.3242 - val_accuracy: 0.6031\n",
      "Epoch 65/150\n",
      "40000/40000 [==============================] - 3s 68us/sample - loss: 2.3917 - accuracy: 0.6048 - val_loss: 2.9212 - val_accuracy: 0.5870\n",
      "Epoch 66/150\n",
      "40000/40000 [==============================] - 3s 75us/sample - loss: 1.8526 - accuracy: 0.6086 - val_loss: 1.2194 - val_accuracy: 0.6129\n",
      "Epoch 67/150\n",
      "40000/40000 [==============================] - 3s 86us/sample - loss: 2.1410 - accuracy: 0.5943 - val_loss: 3.0369 - val_accuracy: 0.6696\n",
      "Epoch 68/150\n",
      "40000/40000 [==============================] - 2s 62us/sample - loss: 1.8769 - accuracy: 0.6108 - val_loss: 0.9396 - val_accuracy: 0.6650\n",
      "Epoch 69/150\n",
      "40000/40000 [==============================] - 2s 62us/sample - loss: 2.0520 - accuracy: 0.6092 - val_loss: 3.1901 - val_accuracy: 0.5467\n",
      "Epoch 70/150\n",
      "40000/40000 [==============================] - 3s 65us/sample - loss: 2.0112 - accuracy: 0.6088 - val_loss: 1.8724 - val_accuracy: 0.4797\n",
      "Epoch 71/150\n",
      "40000/40000 [==============================] - 4s 88us/sample - loss: 1.9043 - accuracy: 0.6087 - val_loss: 2.5046 - val_accuracy: 0.5307\n",
      "Epoch 72/150\n",
      "40000/40000 [==============================] - 2s 61us/sample - loss: 2.0007 - accuracy: 0.6047 - val_loss: 2.0438 - val_accuracy: 0.6216\n",
      "Epoch 73/150\n",
      "40000/40000 [==============================] - 3s 70us/sample - loss: 1.9809 - accuracy: 0.6112 - val_loss: 1.9396 - val_accuracy: 0.4703\n",
      "Epoch 74/150\n",
      "40000/40000 [==============================] - 3s 80us/sample - loss: 2.0070 - accuracy: 0.6061 - val_loss: 2.0650 - val_accuracy: 0.5909\n",
      "Epoch 75/150\n",
      "40000/40000 [==============================] - 3s 75us/sample - loss: 1.8060 - accuracy: 0.6161 - val_loss: 1.3732 - val_accuracy: 0.6813\n",
      "Epoch 76/150\n",
      "40000/40000 [==============================] - 3s 68us/sample - loss: 1.7628 - accuracy: 0.6119 - val_loss: 1.9799 - val_accuracy: 0.5994\n",
      "Epoch 77/150\n",
      "40000/40000 [==============================] - 4s 91us/sample - loss: 1.7837 - accuracy: 0.6153 - val_loss: 1.6830 - val_accuracy: 0.6612\n",
      "Epoch 78/150\n",
      "40000/40000 [==============================] - 3s 84us/sample - loss: 1.9539 - accuracy: 0.6072 - val_loss: 2.0975 - val_accuracy: 0.4480\n",
      "Epoch 79/150\n",
      "40000/40000 [==============================] - 3s 78us/sample - loss: 1.9219 - accuracy: 0.6056 - val_loss: 1.7322 - val_accuracy: 0.6408\n",
      "Epoch 80/150\n",
      "40000/40000 [==============================] - 3s 64us/sample - loss: 1.9239 - accuracy: 0.6113 - val_loss: 4.2090 - val_accuracy: 0.5390\n",
      "Epoch 81/150\n",
      "40000/40000 [==============================] - 2s 61us/sample - loss: 1.8082 - accuracy: 0.6092 - val_loss: 2.1005 - val_accuracy: 0.6412\n",
      "Epoch 82/150\n",
      "40000/40000 [==============================] - 3s 63us/sample - loss: 1.7857 - accuracy: 0.6196 - val_loss: 3.7864 - val_accuracy: 0.6121\n",
      "Epoch 83/150\n",
      "40000/40000 [==============================] - 3s 73us/sample - loss: 1.7645 - accuracy: 0.6141 - val_loss: 2.5508 - val_accuracy: 0.3945\n",
      "Epoch 84/150\n",
      "40000/40000 [==============================] - 3s 76us/sample - loss: 1.7851 - accuracy: 0.6044 - val_loss: 3.2922 - val_accuracy: 0.5169\n",
      "Epoch 85/150\n",
      "40000/40000 [==============================] - 3s 87us/sample - loss: 1.8262 - accuracy: 0.6076 - val_loss: 1.3187 - val_accuracy: 0.6750\n",
      "Epoch 86/150\n",
      "40000/40000 [==============================] - 4s 90us/sample - loss: 1.6590 - accuracy: 0.6195 - val_loss: 1.1710 - val_accuracy: 0.6378\n",
      "Epoch 87/150\n",
      "40000/40000 [==============================] - 3s 77us/sample - loss: 1.7749 - accuracy: 0.6097 - val_loss: 3.6177 - val_accuracy: 0.6319\n",
      "Epoch 88/150\n",
      "40000/40000 [==============================] - 4s 93us/sample - loss: 1.7973 - accuracy: 0.6066 - val_loss: 1.7759 - val_accuracy: 0.6376\n",
      "Epoch 89/150\n",
      "40000/40000 [==============================] - 4s 99us/sample - loss: 1.6619 - accuracy: 0.6202 - val_loss: 1.5579 - val_accuracy: 0.6723\n",
      "Epoch 90/150\n",
      "40000/40000 [==============================] - 5s 126us/sample - loss: 1.5856 - accuracy: 0.6179 - val_loss: 1.8396 - val_accuracy: 0.6600\n",
      "Epoch 91/150\n",
      "40000/40000 [==============================] - 5s 122us/sample - loss: 1.6553 - accuracy: 0.6167 - val_loss: 2.5355 - val_accuracy: 0.5322\n",
      "Epoch 92/150\n",
      "40000/40000 [==============================] - 5s 119us/sample - loss: 1.5682 - accuracy: 0.6169 - val_loss: 1.7001 - val_accuracy: 0.5090\n",
      "Epoch 93/150\n",
      "40000/40000 [==============================] - 3s 83us/sample - loss: 1.6785 - accuracy: 0.6140 - val_loss: 1.5281 - val_accuracy: 0.6772\n",
      "Epoch 94/150\n",
      "40000/40000 [==============================] - 3s 82us/sample - loss: 1.5771 - accuracy: 0.6202 - val_loss: 1.1452 - val_accuracy: 0.6022\n",
      "Epoch 95/150\n",
      "40000/40000 [==============================] - 3s 82us/sample - loss: 1.6062 - accuracy: 0.6144 - val_loss: 1.3867 - val_accuracy: 0.5882\n",
      "Epoch 96/150\n",
      "40000/40000 [==============================] - 3s 84us/sample - loss: 1.4988 - accuracy: 0.6133 - val_loss: 2.1411 - val_accuracy: 0.5958\n",
      "Epoch 97/150\n",
      "40000/40000 [==============================] - 4s 88us/sample - loss: 1.5326 - accuracy: 0.6177 - val_loss: 1.4094 - val_accuracy: 0.6563\n",
      "Epoch 98/150\n",
      "40000/40000 [==============================] - 5s 122us/sample - loss: 1.4963 - accuracy: 0.6238 - val_loss: 1.2987 - val_accuracy: 0.6568\n",
      "Epoch 99/150\n",
      "40000/40000 [==============================] - 3s 85us/sample - loss: 1.4960 - accuracy: 0.6110 - val_loss: 1.1649 - val_accuracy: 0.5930\n",
      "Epoch 100/150\n",
      "40000/40000 [==============================] - 3s 81us/sample - loss: 1.5193 - accuracy: 0.6134 - val_loss: 2.0262 - val_accuracy: 0.4607\n",
      "Epoch 101/150\n",
      "40000/40000 [==============================] - 3s 80us/sample - loss: 1.4851 - accuracy: 0.6177 - val_loss: 1.2527 - val_accuracy: 0.6505\n",
      "Epoch 102/150\n",
      "40000/40000 [==============================] - 3s 85us/sample - loss: 1.4391 - accuracy: 0.6157 - val_loss: 1.3193 - val_accuracy: 0.5183\n",
      "Epoch 103/150\n",
      "40000/40000 [==============================] - 3s 83us/sample - loss: 1.4681 - accuracy: 0.6174 - val_loss: 0.9267 - val_accuracy: 0.6597\n",
      "Epoch 104/150\n",
      "40000/40000 [==============================] - 3s 78us/sample - loss: 1.3086 - accuracy: 0.6248 - val_loss: 1.5591 - val_accuracy: 0.6046\n",
      "Epoch 105/150\n",
      "40000/40000 [==============================] - 3s 80us/sample - loss: 1.4154 - accuracy: 0.6205 - val_loss: 1.0947 - val_accuracy: 0.6384\n",
      "Epoch 106/150\n",
      "40000/40000 [==============================] - 3s 78us/sample - loss: 1.4285 - accuracy: 0.6183 - val_loss: 1.2747 - val_accuracy: 0.6226\n",
      "Epoch 107/150\n",
      "40000/40000 [==============================] - 3s 78us/sample - loss: 1.4718 - accuracy: 0.6169 - val_loss: 1.4753 - val_accuracy: 0.5942\n",
      "Epoch 108/150\n",
      "40000/40000 [==============================] - 3s 86us/sample - loss: 1.2986 - accuracy: 0.6232 - val_loss: 1.6532 - val_accuracy: 0.5379\n",
      "Epoch 109/150\n",
      "40000/40000 [==============================] - 4s 92us/sample - loss: 1.3622 - accuracy: 0.6213 - val_loss: 1.3366 - val_accuracy: 0.5889\n",
      "Epoch 110/150\n",
      "40000/40000 [==============================] - 3s 77us/sample - loss: 1.2861 - accuracy: 0.6277 - val_loss: 1.8988 - val_accuracy: 0.5481\n",
      "Epoch 111/150\n",
      "40000/40000 [==============================] - 4s 108us/sample - loss: 1.2918 - accuracy: 0.6190 - val_loss: 1.0652 - val_accuracy: 0.5571\n",
      "Epoch 112/150\n",
      "40000/40000 [==============================] - 4s 92us/sample - loss: 1.2926 - accuracy: 0.6194 - val_loss: 1.6055 - val_accuracy: 0.6759\n",
      "Epoch 113/150\n",
      "40000/40000 [==============================] - 3s 84us/sample - loss: 1.2265 - accuracy: 0.6218 - val_loss: 1.3610 - val_accuracy: 0.5935\n",
      "Epoch 114/150\n",
      "40000/40000 [==============================] - 4s 88us/sample - loss: 1.1769 - accuracy: 0.6250 - val_loss: 1.1242 - val_accuracy: 0.6301loss: 1\n",
      "Epoch 115/150\n",
      "40000/40000 [==============================] - 3s 75us/sample - loss: 1.1591 - accuracy: 0.6223 - val_loss: 0.9975 - val_accuracy: 0.6091\n",
      "Epoch 116/150\n",
      "40000/40000 [==============================] - 3s 74us/sample - loss: 1.1900 - accuracy: 0.6222 - val_loss: 0.9843 - val_accuracy: 0.6700\n",
      "Epoch 117/150\n",
      "40000/40000 [==============================] - 3s 78us/sample - loss: 1.1034 - accuracy: 0.6276 - val_loss: 1.2855 - val_accuracy: 0.5579\n",
      "Epoch 118/150\n",
      "40000/40000 [==============================] - 3s 76us/sample - loss: 1.1387 - accuracy: 0.6227 - val_loss: 1.2029 - val_accuracy: 0.6105\n",
      "Epoch 119/150\n",
      "40000/40000 [==============================] - 4s 95us/sample - loss: 1.0710 - accuracy: 0.6254 - val_loss: 1.5933 - val_accuracy: 0.6021\n",
      "Epoch 120/150\n",
      "40000/40000 [==============================] - 3s 78us/sample - loss: 1.0689 - accuracy: 0.6256 - val_loss: 0.9480 - val_accuracy: 0.6763\n",
      "Epoch 121/150\n",
      "40000/40000 [==============================] - 4s 96us/sample - loss: 0.9906 - accuracy: 0.6294 - val_loss: 1.1222 - val_accuracy: 0.5649\n",
      "Epoch 122/150\n",
      "40000/40000 [==============================] - 3s 83us/sample - loss: 1.0454 - accuracy: 0.6205 - val_loss: 0.8220 - val_accuracy: 0.6409\n",
      "Epoch 123/150\n",
      "40000/40000 [==============================] - 4s 90us/sample - loss: 1.0040 - accuracy: 0.6322 - val_loss: 1.7590 - val_accuracy: 0.5386\n",
      "Epoch 124/150\n",
      "40000/40000 [==============================] - 3s 85us/sample - loss: 0.9715 - accuracy: 0.6288 - val_loss: 0.8207 - val_accuracy: 0.6312\n",
      "Epoch 125/150\n",
      "40000/40000 [==============================] - 4s 95us/sample - loss: 0.9373 - accuracy: 0.6357 - val_loss: 0.8259 - val_accuracy: 0.6353\n",
      "Epoch 126/150\n",
      "40000/40000 [==============================] - 3s 86us/sample - loss: 0.8632 - accuracy: 0.6430 - val_loss: 0.8496 - val_accuracy: 0.6403\n",
      "Epoch 127/150\n",
      "40000/40000 [==============================] - 3s 83us/sample - loss: 0.8536 - accuracy: 0.6386 - val_loss: 0.8105 - val_accuracy: 0.6546\n",
      "Epoch 128/150\n",
      "40000/40000 [==============================] - 3s 84us/sample - loss: 0.8221 - accuracy: 0.6411 - val_loss: 0.7945 - val_accuracy: 0.6361\n",
      "Epoch 129/150\n",
      "40000/40000 [==============================] - 4s 101us/sample - loss: 0.8171 - accuracy: 0.6408 - val_loss: 0.7959 - val_accuracy: 0.6235\n",
      "Epoch 130/150\n",
      "40000/40000 [==============================] - 4s 99us/sample - loss: 0.7934 - accuracy: 0.6396 - val_loss: 0.7316 - val_accuracy: 0.6422\n",
      "Epoch 131/150\n",
      "40000/40000 [==============================] - 4s 97us/sample - loss: 0.7864 - accuracy: 0.6352 - val_loss: 0.8103 - val_accuracy: 0.6414\n",
      "Epoch 132/150\n",
      "40000/40000 [==============================] - 3s 81us/sample - loss: 0.7789 - accuracy: 0.6309 - val_loss: 0.8413 - val_accuracy: 0.6113\n",
      "Epoch 133/150\n",
      "40000/40000 [==============================] - 3s 81us/sample - loss: 0.7740 - accuracy: 0.6260 - val_loss: 0.7561 - val_accuracy: 0.6322\n",
      "Epoch 134/150\n",
      "40000/40000 [==============================] - 3s 80us/sample - loss: 0.7638 - accuracy: 0.6270 - val_loss: 0.8173 - val_accuracy: 0.5912\n",
      "Epoch 135/150\n",
      "40000/40000 [==============================] - 4s 98us/sample - loss: 0.7551 - accuracy: 0.6315 - val_loss: 0.7584 - val_accuracy: 0.6379\n",
      "Epoch 136/150\n",
      "40000/40000 [==============================] - 4s 88us/sample - loss: 0.7495 - accuracy: 0.6305 - val_loss: 0.7485 - val_accuracy: 0.6324\n",
      "Epoch 137/150\n",
      "40000/40000 [==============================] - 4s 90us/sample - loss: 0.7521 - accuracy: 0.6271 - val_loss: 0.7484 - val_accuracy: 0.6377\n",
      "Epoch 138/150\n",
      "40000/40000 [==============================] - 3s 87us/sample - loss: 0.7443 - accuracy: 0.6313 - val_loss: 0.7521 - val_accuracy: 0.6186\n",
      "Epoch 139/150\n",
      "40000/40000 [==============================] - 4s 110us/sample - loss: 0.7450 - accuracy: 0.6289 - val_loss: 0.7651 - val_accuracy: 0.6102\n",
      "Epoch 140/150\n",
      "40000/40000 [==============================] - 5s 124us/sample - loss: 0.7428 - accuracy: 0.6318 - val_loss: 0.7488 - val_accuracy: 0.6449\n",
      "Epoch 141/150\n",
      "40000/40000 [==============================] - 5s 135us/sample - loss: 0.7258 - accuracy: 0.6492 - val_loss: 0.7151 - val_accuracy: 0.6480\n",
      "Epoch 142/150\n",
      "40000/40000 [==============================] - 5s 121us/sample - loss: 0.7197 - accuracy: 0.6537 - val_loss: 0.7119 - val_accuracy: 0.6610\n",
      "Epoch 143/150\n",
      "40000/40000 [==============================] - 4s 101us/sample - loss: 0.7144 - accuracy: 0.6590 - val_loss: 0.7248 - val_accuracy: 0.6409\n",
      "Epoch 144/150\n",
      "40000/40000 [==============================] - 4s 109us/sample - loss: 0.7097 - accuracy: 0.6616 - val_loss: 0.7185 - val_accuracy: 0.6475\n",
      "Epoch 145/150\n",
      "40000/40000 [==============================] - 3s 83us/sample - loss: 0.7113 - accuracy: 0.6615 - val_loss: 0.7251 - val_accuracy: 0.6653\n",
      "Epoch 146/150\n",
      "40000/40000 [==============================] - 4s 97us/sample - loss: 0.7109 - accuracy: 0.6604 - val_loss: 0.7140 - val_accuracy: 0.6597\n",
      "Epoch 147/150\n",
      "40000/40000 [==============================] - 3s 79us/sample - loss: 0.7038 - accuracy: 0.6645 - val_loss: 0.7436 - val_accuracy: 0.6554\n",
      "Epoch 148/150\n",
      "40000/40000 [==============================] - 3s 74us/sample - loss: 0.7065 - accuracy: 0.6648 - val_loss: 0.7104 - val_accuracy: 0.6532\n",
      "Epoch 149/150\n",
      "40000/40000 [==============================] - 3s 75us/sample - loss: 0.7101 - accuracy: 0.6612 - val_loss: 0.7064 - val_accuracy: 0.6534\n",
      "Epoch 150/150\n",
      "40000/40000 [==============================] - 3s 75us/sample - loss: 0.7013 - accuracy: 0.6668 - val_loss: 0.7097 - val_accuracy: 0.6600\n",
      "saved model in /Users/mengweetan/Desktop/devt/ai/ml_n/\n",
      "<tensorflow.python.keras.callbacks.History object at 0x11f3a2048>\n"
     ]
    }
   ],
   "source": [
    "m.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "load_model = tf.keras.models.load_model\n",
    "model = load_model('_modelv2.h5',custom_objects={'tf': tf}, compile=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 15)                735       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 64        \n",
      "=================================================================\n",
      "Total params: 799\n",
      "Trainable params: 799\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.5097039e-01 1.4536532e-04 1.6739985e-02 7.3214418e-01]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "#input = [0,11932,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0.0,1542,3.3010299956639813,0.0,3.681241237375587,0.0,3.462397997898956,0.0,5.012837224705172,4.0484029561527395,2,0,0,1,0,0,2710,0,1,0,0,0.0,0,0.0,0] #1lk\n",
    "input = [1,10224,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0.0,1177,4.792454727670386,4.091491094267951,4.685222065334621,2.552668216112193,3.9030899869919438,0.0,0.0,0.0,0,2,0,0,1,0,0,0,1,0,0,0.0,0,0.0,1] #1000\n",
    "#input = [1,23779,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,4.346352974450639,10491,0.0,0.0,4.013427127070696,0.0,0.0,0.0,4.621124329567078,4.0092383709684665,0,0,0,1,0,0,13043,0,0,1,0,0.0,0,0.0,0] #800\n",
    "#input = [1,13678,1,1,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0.0,386,0.0,0.0,3.97799780995874,4.17897694729317,3.547528576459782,0.0,4.89368965098515,4.354146870586911,1,0,0,1,0,0,2171,0,1,0,0,0.0,0,-0.07583333333333332,1] #800\n",
    "#input = [1,13336,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0.0,537,0.0,0.0,4.452430493699599,4.4123261221462435,0.0,0.0,4.655503396249793,3.3820170425748683,1,0,0,1,0,0,2500,0,1,0,0,0.0,0,0.03333333333333333,1] #1k\n",
    "#input = [0,17792,1,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,4.357934847000454,4920,4.556302500767287,0.0,4.477121254719663,0.0,3.8750612633917,0.0,4.832508912706237,4.230448921378274,2,2,0,1,0,0,8657,0,0,1,0,0.0,0,0.0,0] #800\n",
    "\n",
    "#input = [0, 20822, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3.8785217955012063, 0, 0, 0, 4.109747237713228, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, -1, -99, 0]\n",
    "#input = [1, 20880, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 902, 3.964118143151485, 3.964118143151485, 3.2593549273080344, 3.2593549273080344, 3.3010299956639813, 3.3010299956639813, 3.964118143151485, 3.9242792860618816, 0, 0, 0, 1, 0, 0, 11275, 0, 1, 0, 0, 0, -1, 0.004444444444444445, 1]\n",
    "\n",
    "_i = np.reshape(input,(len(input),1))\n",
    "\n",
    "_a = model.predict([_i.T])\n",
    "print (_a)\n",
    "np.argmax(_a)  #0 = 0,1=400, 2=800, 3 = 1k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.y[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
