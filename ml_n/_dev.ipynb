{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil.parser import parse\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "\n",
    "samplesize = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mengweetan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob #sentiment analysis\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "\n",
    "def _gender(data):\n",
    "    try:\n",
    "        if data and data.lower()=='male': return 1\n",
    "        else: return 0\n",
    "    except: return -1\n",
    "    \n",
    "def _age(data):\n",
    "    try:\n",
    "        if data and str(data) !='nan':\n",
    "            bd = parse(data)\n",
    "            diff = datetime.now() - bd\n",
    "            return diff.days \n",
    "        else: return 0\n",
    "    except Exception as e: \n",
    "        print (e)\n",
    "        print (data)\n",
    "        return -1\n",
    "    \n",
    "def _nationality(data):\n",
    "    if data and 'singapore' in data.lower(): return 1   \n",
    "    else: return 0\n",
    "    \n",
    "def _resi_status(data):\n",
    "    if data and  data.lower() == 'citizen' or  data.lower() == 'pr': return 1   \n",
    "    else: return 0\n",
    "    \n",
    "def _yesno(data):\n",
    "    if data:\n",
    "        if str(data).lower() == 'yes' : return 1 \n",
    "        else: return 0\n",
    "    else: return -1\n",
    "    \n",
    "def _occupation(data):\n",
    "    if data and 'tour' in str(data).lower(): return 1   \n",
    "    else: return 0\n",
    "    \n",
    "def _self_employ_time(data):\n",
    "    import calendar\n",
    "    try:\n",
    "        if data and str(data) != 'nan':\n",
    "            \n",
    "            \n",
    "            _m = list(calendar.month_abbr).index(data.split(\";\")[0]) \n",
    "\n",
    "            \n",
    "\n",
    "            __y = data.split(\";\")[1].replace('Before','').replace(' ','') # get rid of silly \"Before\"\n",
    "            _y = int(__y)\n",
    "\n",
    "            #print ( (datetime.now() -   datetime(_y,_m,1)).days)\n",
    "            return (datetime.now() -   datetime(_y,_m,1)).days\n",
    "            #else: \n",
    "            #    ym = data.split(';')[2]\n",
    "            #    _y = int(ym.split(\"-\")[0])\n",
    "            #    _m = int(ym.split(\"-\")[1])\n",
    "            #    return (datetime.now() -   datetime(_y,_m,1)).days\n",
    "                \n",
    "        else: return 0\n",
    "    except Exception as e: \n",
    "        print ('mthyear exception')\n",
    "        print (data)\n",
    "        print (e)\n",
    "        return -10\n",
    "    \n",
    "\n",
    "    \n",
    "def _log(data):\n",
    "    try:\n",
    "        #print (para)\n",
    "        if data and float(data)>0:return math.log10(float(data))\n",
    "        else: return 0\n",
    "    except Exception as e: \n",
    "        #print (e)\n",
    "        return -1\n",
    "def _int(data):\n",
    "    if data and str(data) != 'nan': return int(data)\n",
    "    else: return -1\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "import statistics\n",
    "def _sentiment_of(text):\n",
    "    if text:\n",
    "        blob = TextBlob(str(text))\n",
    "        _sentiments = []\n",
    "        for sentence in blob.sentences:\n",
    "            _sentiments.append(sentence.sentiment.polarity * sentence.sentiment.subjectivity)\n",
    "        return  statistics.mean(_sentiments) \n",
    "    else: return -10\n",
    "    \n",
    "def _interested(data):\n",
    "    if data and 'contact' in str(data): return 1\n",
    "    else: return 0\n",
    "    \n",
    "def _evaluate_checker(data):\n",
    "    if data and str(data) != 'nan':\n",
    "        try:\n",
    "            _checker = data.split(\";\")[0] \n",
    "            if _checker != '' and str(_checker) != 'nan' and str(_checker) == 'ESCALATE' : return -1\n",
    "            elif _checker == '' or str(_checker) == 'nan':\n",
    "                _checker = data.split(\";\")[1]\n",
    "                \n",
    "                \n",
    "                if _checker != '' and str(_checker) != 'nan' and str(_checker) == 'ESCALATE': return -1\n",
    "                elif _checker == '' or str(_checker) == 'nan': return -10\n",
    "                else: return float(_checker)\n",
    "            \n",
    "            \n",
    "            else:  return float(_checker)\n",
    "                \n",
    "            \n",
    "        except Exception as e: \n",
    "            print (e)\n",
    "            return -10\n",
    "        \n",
    "    else: return -10\n",
    "    \n",
    "def _f(n):\n",
    "    return str(n)\n",
    "\n",
    "def _label_outcome(data):\n",
    "    if data:\n",
    "        if str(data) == 'Approve - 1000': return 1000\n",
    "        elif str(data) == 'Approve - 800': return 800\n",
    "        elif str(data) == 'Approve - 400': return 400\n",
    "        else: return 0\n",
    "    else: return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "50%\n",
      "60%\n",
      "80%\n",
      "90%\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv('output2.csv', dtype='unicode') # this is the final file!\n",
    "\n",
    "\n",
    "#_result = df[0:samplesize]\n",
    "_result = df\n",
    "print ('start')\n",
    "old_columns = [i for i in _result.columns]\n",
    "#print (old_columns)\n",
    "\n",
    "_result['_gender']=_result['Gender'].apply(_gender)\n",
    "_result['_age']=_result['Date of Birth'].apply(_age)\n",
    "_result['_nationality']=_result['Nationality'].apply(_nationality)\n",
    "_result['_resi_status']=_result['Residential Status'].apply(_resi_status)\n",
    "\n",
    "_result = pd.concat([_result,pd.get_dummies(_result['Housing Type'], prefix='onehot')],axis=1)\n",
    "_result['_hdb_registered_address']=_result['Registered Address'].apply(_yesno)\n",
    "_result = pd.concat([_result,pd.get_dummies(_result['Highest Education'], prefix='onehot')],axis=1)\n",
    "_result['_occupation']=_result['Occupation'].apply(_occupation)\n",
    "#_result['_av']=_result['Annual Value (AV) of  registered address'].apply(_av,args=(-1,))\n",
    "_result['_av_value']=_result['Annual Value (AV) of  registered address'].apply(_log)\n",
    "\n",
    "_result['__temp']=_result['Self Employed Since (Month)']+';'+_result['Self Employed Since (Year)']\n",
    "_result['_self_employ_time']=_result['__temp'].apply(_self_employ_time)\n",
    "\n",
    "\n",
    "        \n",
    "print ('50%') \n",
    "_result['_2018_t']=_result['Income in 2018 (NOA YA2019) - Trade income'].apply(_log)\n",
    "_result['_2018_e']=_result['\\xa0Income in 2018 (NOA YA2019) - Employment income'].apply(_log)\n",
    "_result['_2019_e']=_result['Income in 2019 (NOA YA2020) - Trade income'].apply(_log)\n",
    "_result['_2019_t']=_result['Income in 2019 (NOA YA2020) - Employment income'].apply(_log)\n",
    "_result['_2020_e']=_result['Income in 2020 (Jan-Mar) - Trade income'].apply(_log)\n",
    "_result['_2020_t']=_result['Income in 2020 (Jan-Mar) - Employment income'].apply(_log)\n",
    "_result['s_2019_i']=_result['Spouse\\'s Income in 2019'].apply(_log)\n",
    "_result['s_2020_i']=_result['Spouse\\'s Income in 2020 (Jan-Mar)'].apply(_log)\n",
    "\n",
    "_result['_child']=_result['No. of Singaporean Children < 21'].apply(_int)\n",
    "_result['_parent']=_result['No. of Singaporean Parents > 64'].apply(_int)\n",
    "print ('60%') \n",
    "_result = pd.concat([_result,pd.get_dummies(_result['Marital Status'], prefix='onehot')],axis=1)\n",
    "_result['_married']=_result['Marriage Date'].apply(_age)\n",
    "_result['_divorced']=_result['Divorce Date'].apply(_age)\n",
    "\n",
    "_result['_hdb']=_result['Number of HDB properties own'].apply(_int)\n",
    "_result['_pte']=_result['Number of private properties own'].apply(_int)\n",
    "_result['_comz']=_result['Number of commercial properties own'].apply(_int)\n",
    "_result['_comz_av']=_result['Annual Value (AV) of commercial properties own'].apply(_log)\n",
    "_result['_comz_operate']=_result['Biz Operations from  commercial properties'].apply(_yesno)\n",
    "print ('80%') \n",
    "\n",
    "_result['_hardship_sentiment']=_result['Please describe hardship (if any)'].apply(_sentiment_of)\n",
    "print ('90%') \n",
    "_result['_ntuc_covid']=_result['Interested in NTUC Covid19 Programme'].apply(_interested)\n",
    "\n",
    "#_result['__temp2']=_result['Checker Outcome\\nValue'].str +';'+_result['Checker Outcome\\nNew'].str  # checker!\n",
    "_result['Checker Outcome\\nValue'] = _result['Checker Outcome\\nValue'].apply(_f) \n",
    "_result['Checker Outcome\\nNew'] = _result['Checker Outcome\\nNew'].apply(_f) \n",
    "_result['__temp2']= _result[['Checker Outcome\\nValue', 'Checker Outcome\\nNew']].agg(';'.join, axis=1)\n",
    "_result['_checker']=_result['__temp2'].apply(_evaluate_checker)\n",
    "\n",
    "_result['LABEL']=_result['Final Outcome Combined'].apply(_label_outcome)\n",
    "\n",
    "\n",
    "_result = _result.drop(old_columns,axis=1)\n",
    "print ('end')\n",
    "\n",
    "_result.to_csv ('_final.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from machine import Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72669, 49)\n",
      "(72669, 4)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 15)                750       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 64        \n",
      "=================================================================\n",
      "Total params: 814\n",
      "Trainable params: 814\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "m = Machine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 58135 samples, validate on 14534 samples\n",
      "Epoch 1/150\n",
      "58135/58135 [==============================] - 4s 73us/sample - loss: 104.6483 - accuracy: 0.6070 - val_loss: 2.3729 - val_accuracy: 0.6912\n",
      "Epoch 2/150\n",
      "58135/58135 [==============================] - 4s 64us/sample - loss: 4.9305 - accuracy: 0.6416 - val_loss: 1.8985 - val_accuracy: 0.6973\n",
      "Epoch 3/150\n",
      "58135/58135 [==============================] - 4s 66us/sample - loss: 4.0866 - accuracy: 0.6391 - val_loss: 2.9888 - val_accuracy: 0.6775\n",
      "Epoch 4/150\n",
      "58135/58135 [==============================] - 4s 65us/sample - loss: 3.0514 - accuracy: 0.6432 - val_loss: 1.1793 - val_accuracy: 0.5740\n",
      "Epoch 5/150\n",
      "58135/58135 [==============================] - 4s 72us/sample - loss: 2.3669 - accuracy: 0.6443 - val_loss: 1.6400 - val_accuracy: 0.5641\n",
      "Epoch 6/150\n",
      "58135/58135 [==============================] - 5s 84us/sample - loss: 2.2997 - accuracy: 0.6427 - val_loss: 1.2103 - val_accuracy: 0.6883\n",
      "Epoch 7/150\n",
      "58135/58135 [==============================] - 4s 61us/sample - loss: 2.4442 - accuracy: 0.6432 - val_loss: 1.9996 - val_accuracy: 0.6334\n",
      "Epoch 8/150\n",
      "58135/58135 [==============================] - 4s 65us/sample - loss: 2.2950 - accuracy: 0.6454 - val_loss: 2.0824 - val_accuracy: 0.5528\n",
      "Epoch 9/150\n",
      "58135/58135 [==============================] - 4s 69us/sample - loss: 2.2905 - accuracy: 0.6465 - val_loss: 2.0002 - val_accuracy: 0.5447\n",
      "Epoch 10/150\n",
      "58135/58135 [==============================] - 5s 79us/sample - loss: 2.2008 - accuracy: 0.6462 - val_loss: 1.2454 - val_accuracy: 0.6818\n",
      "Epoch 11/150\n",
      "58135/58135 [==============================] - 5s 87us/sample - loss: 2.0989 - accuracy: 0.6500 - val_loss: 0.9293 - val_accuracy: 0.6854\n",
      "Epoch 12/150\n",
      "58135/58135 [==============================] - 5s 84us/sample - loss: 2.0534 - accuracy: 0.6486 - val_loss: 1.3624 - val_accuracy: 0.6772\n",
      "Epoch 13/150\n",
      "58135/58135 [==============================] - 5s 79us/sample - loss: 2.0397 - accuracy: 0.6479 - val_loss: 2.3496 - val_accuracy: 0.7049\n",
      "Epoch 14/150\n",
      "58135/58135 [==============================] - 4s 67us/sample - loss: 1.9669 - accuracy: 0.6528 - val_loss: 1.6686 - val_accuracy: 0.6227\n",
      "Epoch 15/150\n",
      "58135/58135 [==============================] - 4s 67us/sample - loss: 1.8717 - accuracy: 0.6527 - val_loss: 1.4967 - val_accuracy: 0.7092\n",
      "Epoch 16/150\n",
      "58135/58135 [==============================] - 7s 121us/sample - loss: 1.6699 - accuracy: 0.6551 - val_loss: 1.3478 - val_accuracy: 0.7046\n",
      "Epoch 17/150\n",
      "58135/58135 [==============================] - 4s 72us/sample - loss: 1.8475 - accuracy: 0.6522 - val_loss: 1.3677 - val_accuracy: 0.7043\n",
      "Epoch 18/150\n",
      "58135/58135 [==============================] - 4s 69us/sample - loss: 1.6873 - accuracy: 0.6514 - val_loss: 1.2564 - val_accuracy: 0.6905\n",
      "Epoch 19/150\n",
      "58135/58135 [==============================] - 4s 68us/sample - loss: 1.6233 - accuracy: 0.6547 - val_loss: 1.6099 - val_accuracy: 0.7098\n",
      "Epoch 20/150\n",
      "58135/58135 [==============================] - 4s 70us/sample - loss: 1.5817 - accuracy: 0.6530 - val_loss: 1.1038 - val_accuracy: 0.6995\n",
      "Epoch 21/150\n",
      "58135/58135 [==============================] - 4s 67us/sample - loss: 1.6166 - accuracy: 0.6556 - val_loss: 1.5610 - val_accuracy: 0.6155\n",
      "Epoch 22/150\n",
      "58135/58135 [==============================] - 4s 69us/sample - loss: 1.3964 - accuracy: 0.6620 - val_loss: 1.7296 - val_accuracy: 0.5429\n",
      "Epoch 23/150\n",
      "58135/58135 [==============================] - 4s 70us/sample - loss: 1.3488 - accuracy: 0.6595 - val_loss: 1.7001 - val_accuracy: 0.7084\n",
      "Epoch 24/150\n",
      "58135/58135 [==============================] - 4s 74us/sample - loss: 1.2986 - accuracy: 0.6640 - val_loss: 1.2439 - val_accuracy: 0.6191\n",
      "Epoch 25/150\n",
      "58135/58135 [==============================] - 5s 83us/sample - loss: 1.4448 - accuracy: 0.6640 - val_loss: 1.0371 - val_accuracy: 0.6561\n",
      "Epoch 26/150\n",
      "58135/58135 [==============================] - 4s 69us/sample - loss: 1.1262 - accuracy: 0.6721 - val_loss: 1.2361 - val_accuracy: 0.5611\n",
      "Epoch 27/150\n",
      "58135/58135 [==============================] - 4s 68us/sample - loss: 1.0811 - accuracy: 0.6694 - val_loss: 1.7316 - val_accuracy: 0.5660\n",
      "Epoch 28/150\n",
      "58135/58135 [==============================] - 4s 72us/sample - loss: 1.0520 - accuracy: 0.6711 - val_loss: 0.6302 - val_accuracy: 0.6935\n",
      "Epoch 29/150\n",
      "58135/58135 [==============================] - 4s 76us/sample - loss: 0.9817 - accuracy: 0.6740 - val_loss: 1.2796 - val_accuracy: 0.7062\n",
      "Epoch 30/150\n",
      "58135/58135 [==============================] - 5s 84us/sample - loss: 0.9661 - accuracy: 0.6732 - val_loss: 1.1324 - val_accuracy: 0.5722\n",
      "Epoch 31/150\n",
      "58135/58135 [==============================] - 4s 74us/sample - loss: 1.0516 - accuracy: 0.6789 - val_loss: 0.6075 - val_accuracy: 0.7092\n",
      "Epoch 32/150\n",
      "58135/58135 [==============================] - 5s 78us/sample - loss: 0.7859 - accuracy: 0.6853 - val_loss: 0.6296 - val_accuracy: 0.7122\n",
      "Epoch 33/150\n",
      "58135/58135 [==============================] - 4s 69us/sample - loss: 0.7601 - accuracy: 0.6874 - val_loss: 0.8215 - val_accuracy: 0.6303\n",
      "Epoch 34/150\n",
      "58135/58135 [==============================] - 4s 69us/sample - loss: 0.7209 - accuracy: 0.6910 - val_loss: 0.7335 - val_accuracy: 0.6971\n",
      "Epoch 35/150\n",
      "58135/58135 [==============================] - 4s 69us/sample - loss: 0.6799 - accuracy: 0.6947 - val_loss: 0.7016 - val_accuracy: 0.7059\n",
      "Epoch 36/150\n",
      "58135/58135 [==============================] - 4s 69us/sample - loss: 0.6253 - accuracy: 0.6984 - val_loss: 0.6164 - val_accuracy: 0.6938\n",
      "Epoch 37/150\n",
      "58135/58135 [==============================] - 4s 69us/sample - loss: 0.6047 - accuracy: 0.7035 - val_loss: 0.5976 - val_accuracy: 0.7103\n",
      "Epoch 38/150\n",
      "58135/58135 [==============================] - 4s 70us/sample - loss: 0.5970 - accuracy: 0.7043 - val_loss: 0.5976 - val_accuracy: 0.6995\n",
      "Epoch 39/150\n",
      "58135/58135 [==============================] - 4s 73us/sample - loss: 0.5984 - accuracy: 0.7038 - val_loss: 0.5964 - val_accuracy: 0.7063\n",
      "Epoch 40/150\n",
      "58135/58135 [==============================] - 4s 69us/sample - loss: 0.5945 - accuracy: 0.7058 - val_loss: 0.5903 - val_accuracy: 0.7097\n",
      "Epoch 41/150\n",
      "58135/58135 [==============================] - 5s 78us/sample - loss: 0.5931 - accuracy: 0.7075 - val_loss: 0.5846 - val_accuracy: 0.7071\n",
      "Epoch 42/150\n",
      "58135/58135 [==============================] - 4s 75us/sample - loss: 0.5920 - accuracy: 0.7063 - val_loss: 0.5825 - val_accuracy: 0.7137\n",
      "Epoch 43/150\n",
      "58135/58135 [==============================] - 5s 78us/sample - loss: 0.5876 - accuracy: 0.7073 - val_loss: 0.5851 - val_accuracy: 0.7124\n",
      "Epoch 44/150\n",
      "58135/58135 [==============================] - 5s 81us/sample - loss: 0.5873 - accuracy: 0.7070 - val_loss: 0.6023 - val_accuracy: 0.7028\n",
      "Epoch 45/150\n",
      "58135/58135 [==============================] - 6s 97us/sample - loss: 0.5857 - accuracy: 0.7078 - val_loss: 0.6034 - val_accuracy: 0.7094\n",
      "Epoch 46/150\n",
      "58135/58135 [==============================] - 4s 72us/sample - loss: 0.5838 - accuracy: 0.7096 - val_loss: 0.6388 - val_accuracy: 0.6517\n",
      "Epoch 47/150\n",
      "58135/58135 [==============================] - 5s 92us/sample - loss: 0.5838 - accuracy: 0.7091 - val_loss: 0.5892 - val_accuracy: 0.7005\n",
      "Epoch 48/150\n",
      "58135/58135 [==============================] - 5s 86us/sample - loss: 0.5816 - accuracy: 0.7103 - val_loss: 0.5721 - val_accuracy: 0.7151\n",
      "Epoch 49/150\n",
      "58135/58135 [==============================] - 5s 94us/sample - loss: 0.5818 - accuracy: 0.7093 - val_loss: 0.5753 - val_accuracy: 0.7155\n",
      "Epoch 50/150\n",
      "58135/58135 [==============================] - 5s 89us/sample - loss: 0.5787 - accuracy: 0.7101 - val_loss: 0.5727 - val_accuracy: 0.7156\n",
      "Epoch 51/150\n",
      "58135/58135 [==============================] - 5s 86us/sample - loss: 0.5777 - accuracy: 0.7110 - val_loss: 0.5719 - val_accuracy: 0.7111\n",
      "Epoch 52/150\n",
      "58135/58135 [==============================] - 5s 86us/sample - loss: 0.5802 - accuracy: 0.7084 - val_loss: 0.5850 - val_accuracy: 0.7121\n",
      "Epoch 53/150\n",
      "58135/58135 [==============================] - 5s 80us/sample - loss: 0.5789 - accuracy: 0.7096 - val_loss: 0.6468 - val_accuracy: 0.6512\n",
      "Epoch 54/150\n",
      "58135/58135 [==============================] - 6s 96us/sample - loss: 0.5783 - accuracy: 0.7096 - val_loss: 0.5833 - val_accuracy: 0.7143\n",
      "Epoch 55/150\n",
      "58135/58135 [==============================] - 4s 76us/sample - loss: 0.5797 - accuracy: 0.7096 - val_loss: 0.6367 - val_accuracy: 0.7083\n",
      "Epoch 56/150\n",
      "58135/58135 [==============================] - 5s 89us/sample - loss: 0.5784 - accuracy: 0.7094 - val_loss: 0.6113 - val_accuracy: 0.6697\n",
      "Epoch 57/150\n",
      "58135/58135 [==============================] - 6s 102us/sample - loss: 0.5779 - accuracy: 0.7098 - val_loss: 0.5759 - val_accuracy: 0.7127\n",
      "Epoch 58/150\n",
      "58135/58135 [==============================] - 5s 78us/sample - loss: 0.5794 - accuracy: 0.7068 - val_loss: 0.5712 - val_accuracy: 0.7130\n",
      "Epoch 59/150\n",
      "58135/58135 [==============================] - 5s 81us/sample - loss: 0.5760 - accuracy: 0.7098 - val_loss: 0.5772 - val_accuracy: 0.7130\n",
      "Epoch 60/150\n",
      "58135/58135 [==============================] - 5s 78us/sample - loss: 0.5757 - accuracy: 0.7096 - val_loss: 0.5889 - val_accuracy: 0.7096\n",
      "Epoch 61/150\n",
      "58135/58135 [==============================] - 4s 73us/sample - loss: 0.5778 - accuracy: 0.7094 - val_loss: 0.5832 - val_accuracy: 0.7172\n",
      "Epoch 62/150\n",
      "58135/58135 [==============================] - 5s 84us/sample - loss: 0.5890 - accuracy: 0.7069 - val_loss: 0.5793 - val_accuracy: 0.7116\n",
      "Epoch 63/150\n",
      "58135/58135 [==============================] - 5s 78us/sample - loss: 0.5748 - accuracy: 0.7115 - val_loss: 0.5785 - val_accuracy: 0.7096\n",
      "Epoch 64/150\n",
      "58135/58135 [==============================] - 5s 84us/sample - loss: 0.5776 - accuracy: 0.7089 - val_loss: 0.5796 - val_accuracy: 0.7151\n",
      "Epoch 65/150\n",
      "58135/58135 [==============================] - 4s 69us/sample - loss: 0.5774 - accuracy: 0.7091 - val_loss: 0.5763 - val_accuracy: 0.7101\n",
      "Epoch 66/150\n",
      "58135/58135 [==============================] - 4s 68us/sample - loss: 0.5773 - accuracy: 0.7092 - val_loss: 0.5806 - val_accuracy: 0.7152\n",
      "Epoch 67/150\n",
      "58135/58135 [==============================] - 4s 70us/sample - loss: 0.5735 - accuracy: 0.7116 - val_loss: 0.5754 - val_accuracy: 0.7147\n",
      "Epoch 68/150\n",
      "58135/58135 [==============================] - 4s 69us/sample - loss: 0.5779 - accuracy: 0.7094 - val_loss: 0.5898 - val_accuracy: 0.7128\n",
      "Epoch 69/150\n",
      "58135/58135 [==============================] - 4s 70us/sample - loss: 0.5763 - accuracy: 0.7092 - val_loss: 0.6060 - val_accuracy: 0.6971\n",
      "Epoch 70/150\n",
      "58135/58135 [==============================] - 4s 75us/sample - loss: 0.5753 - accuracy: 0.7098 - val_loss: 0.5714 - val_accuracy: 0.7140\n",
      "Epoch 71/150\n",
      "58135/58135 [==============================] - 4s 75us/sample - loss: 0.5759 - accuracy: 0.7105 - val_loss: 0.5799 - val_accuracy: 0.7102\n",
      "Epoch 72/150\n",
      "58135/58135 [==============================] - 4s 69us/sample - loss: 0.5764 - accuracy: 0.7108 - val_loss: 0.5700 - val_accuracy: 0.7164\n",
      "Epoch 73/150\n",
      "58135/58135 [==============================] - 4s 69us/sample - loss: 0.5752 - accuracy: 0.7108 - val_loss: 0.5760 - val_accuracy: 0.7136\n",
      "Epoch 74/150\n",
      "58135/58135 [==============================] - 4s 69us/sample - loss: 0.5764 - accuracy: 0.7083 - val_loss: 0.5726 - val_accuracy: 0.7165\n",
      "Epoch 75/150\n",
      "58135/58135 [==============================] - 4s 71us/sample - loss: 0.5727 - accuracy: 0.7127 - val_loss: 0.5680 - val_accuracy: 0.7158\n",
      "Epoch 76/150\n",
      "58135/58135 [==============================] - 6s 104us/sample - loss: 0.5755 - accuracy: 0.7102 - val_loss: 0.5944 - val_accuracy: 0.6901\n",
      "Epoch 77/150\n",
      "58135/58135 [==============================] - 4s 75us/sample - loss: 0.5743 - accuracy: 0.7093 - val_loss: 0.5983 - val_accuracy: 0.6843\n",
      "Epoch 78/150\n",
      "58135/58135 [==============================] - 4s 71us/sample - loss: 0.5764 - accuracy: 0.7093 - val_loss: 0.5810 - val_accuracy: 0.6982\n",
      "Epoch 79/150\n",
      "58135/58135 [==============================] - 4s 71us/sample - loss: 0.5756 - accuracy: 0.7098 - val_loss: 0.5946 - val_accuracy: 0.7104\n",
      "Epoch 80/150\n",
      "58135/58135 [==============================] - 4s 70us/sample - loss: 0.5739 - accuracy: 0.7102 - val_loss: 0.5723 - val_accuracy: 0.7163\n",
      "Epoch 81/150\n",
      "58135/58135 [==============================] - 4s 75us/sample - loss: 0.5728 - accuracy: 0.7098 - val_loss: 0.5779 - val_accuracy: 0.7107\n",
      "Epoch 82/150\n",
      "58135/58135 [==============================] - 5s 79us/sample - loss: 0.5742 - accuracy: 0.7113 - val_loss: 0.5707 - val_accuracy: 0.7169\n",
      "Epoch 83/150\n",
      "58135/58135 [==============================] - 4s 73us/sample - loss: 0.5744 - accuracy: 0.7107 - val_loss: 0.5711 - val_accuracy: 0.7108\n",
      "Epoch 84/150\n",
      "58135/58135 [==============================] - 4s 73us/sample - loss: 0.5739 - accuracy: 0.7110 - val_loss: 0.5802 - val_accuracy: 0.7100\n",
      "Epoch 85/150\n",
      "58135/58135 [==============================] - 4s 71us/sample - loss: 0.5749 - accuracy: 0.7103 - val_loss: 0.6243 - val_accuracy: 0.7079\n",
      "Epoch 86/150\n",
      "58135/58135 [==============================] - 4s 73us/sample - loss: 0.5748 - accuracy: 0.7100 - val_loss: 0.5731 - val_accuracy: 0.7129\n",
      "Epoch 87/150\n",
      "58135/58135 [==============================] - 4s 74us/sample - loss: 0.5740 - accuracy: 0.7102 - val_loss: 0.5774 - val_accuracy: 0.7084\n",
      "Epoch 88/150\n",
      "58135/58135 [==============================] - 5s 85us/sample - loss: 0.5740 - accuracy: 0.7104 - val_loss: 0.5858 - val_accuracy: 0.7159\n",
      "Epoch 89/150\n",
      "58135/58135 [==============================] - 4s 72us/sample - loss: 0.5748 - accuracy: 0.7100 - val_loss: 0.5749 - val_accuracy: 0.7140\n",
      "Epoch 90/150\n",
      "58135/58135 [==============================] - 5s 95us/sample - loss: 0.5729 - accuracy: 0.7116 - val_loss: 0.5676 - val_accuracy: 0.7174\n",
      "Epoch 91/150\n",
      "57984/58135 [============================>.] - ETA: 0s - loss: 0.5766 - accuracy: 0.7077"
     ]
    }
   ],
   "source": [
    "m.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "load_model = tf.keras.models.load_model\n",
    "model = load_model('_modelv2.h5',custom_objects={'tf': tf}, compile=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 15)                735       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 64        \n",
      "=================================================================\n",
      "Total params: 799\n",
      "Trainable params: 799\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.07054138e-01 1.09936984e-04 3.91905494e-02 2.53645360e-01]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "input = [1,16748,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0.0,507,0.0,0.0,2.24551266781415,4.3448440193371205,2.552668216112193,3.5531545481696254,4.47567118832443,3.845098040014257,1,1,0,1,0,0,6005,0,1,0,0,0.0,0,0.026813888888888894,1,1000.0] #1000\n",
    "_i = np.reshape(input,(len(input),1))\n",
    "\n",
    "_a = model.predict([_i.T])\n",
    "print (_a)\n",
    "np.argmax(_a)  #0 = 0,1=400, 2=800, 3 = 1k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
